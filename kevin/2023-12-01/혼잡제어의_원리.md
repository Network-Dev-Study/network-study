# 혼잡제어의 원리

## 혼잡의 원인과 비용

3가지 시나리오를 살펴 볼 것이다.

### 시나리오1: 2개의 송신자와 무한 버퍼를 갖는 하나의 라우터

- 가장 간단한 시나리오
- 아래 그림 처럼 출발지와 목적지 사이에 단일 홉을 공유하는 연결을 갖는다고 생각해보자

![Untitled](https://user-images.githubusercontent.com/86337233/211454689-76fb01a5-de4b-4556-a80b-fc908571ceda.png)

호스트 A의 애플리케이션이 람다바이트/초의 평균 전송률로 연결상으로 데이터를 보낼 때,

하위 트랜스포트 계층에서 UDP처럼 데이터를 전송하면

호스트 A가 라우터에게 제공하는 속도는 람다(in)바이트/초가 된다.

호스트 B도 속도는 비슷한 방식으로 동작한다고 가정한다.

호스트 A와 호스트 B가 전송되는 패킷은 라우터와 용량 R의 공유 출력링크를 통과한다.

라우터는 출력 링크의 용량을 초과하여 입력되는 패킷들을 저장하는 버퍼를 갖고 있다.

여기서 라우터는 무제한의 버퍼 공간을 갖는다고 가정한다.

아래 그림을 보면 둘 다 첫번째 시나리오에서 호스트 A의 연결 성능을 나타낸 것이다.

a는 연결 전송률의 함수로 수신자 측의 연결당 처리량을 보여준다.

람다(out)에서 0과 R/2사이의 전송률에 대해 수신자 측의 처리량은 송신자의 처리량과 같지만, R/2를 넘어서면 처리량은 R/2로 일정해진다.

링크는 안정 상태에서 R/2를 초과하여 패킷을 수신자에게 전달할 수 없다.(출력 링크에서 용량 R의 공유 출력 링크를 통과하기 때문이다.)

![Untitled](https://user-images.githubusercontent.com/86337233/211454696-58c0e5d1-ece7-4eaf-ab49-12ca7b243f3e.png)

아래 부분은 링크 용량 근처에서 동작의 결과들을 보여준다.

위의 그래프처럼 R/2만큼 풀로 사용하는 것은 좋은 현상이지만, 평균 지연 시간은 점점 커진다.

만약 전송률이 R/2를 초과한다면, 라우터 안에 큐잉된 패킷의 평균 개수는 제한되지 않고 출발지와 목적지 사이의 평균 지연이 무제한이 된다.

따라서 처리량 관점에서 보면 이상적이지만, 지연 관점에서 보면 이상적이지 않다.

![Untitled](https://user-images.githubusercontent.com/86337233/211454693-638ed740-069f-498a-9928-1da5aad7544b.png)

### 시나리오2: 2개의 송신자, 유한 버퍼를 가진 하나의 라우터

시나리오 1을 아래 그림처럼 약간 바꿔보면,

1. 라우터 버퍼의 양은 무한하고, 버퍼가 가득차면, 도착한 패킷들은 버려진다.
2. 각 연결은 신뢰적이라 가정한다. 람다(in)아래 재전송 기능이 생겼다.(재전송 기능은 네트워크에서 제공된 부하라고 부른다.)

![Untitled](https://user-images.githubusercontent.com/86337233/211454689-76fb01a5-de4b-4556-a80b-fc908571ceda.png)

아래 그림은 다음 재전송의 상황에 따라 다른 그래프의 모습이다.

![Untitled](https://user-images.githubusercontent.com/86337233/211454701-c4833238-04e5-4e71-930a-da27777bcec6.png)

a: 호스트 A가 수신자의 버퍼를 알고 있고, 수신자의 버퍼가 비어 있을 때만 전송하는 경우이다.

이 경우 어떤 손실도 발생하지 않고 연결의 처리량은 람다(in)과 같다.

b: 패킷이 확실히 손실되었을 경우를 안다면 송신자가 재전송하는 경우다.

이 경우 송신자가 R/2만큼 전송해도 실질적으로 송신자가 받는 데이터의 전송률은 R/3정도가 된다.

(그냥 보낸 양이 R/3이고 나머지 R/6(=0.166…)정도는 재전송된 것이다.)

c: 송신자에서 너무 일찍 타임아웃 되어 버려 패킷이 손실되지 않았지만, 큐에서 지연된 패킷을 재전송하는 경우이다.

이 경우 둘 다 도착해 버리므로 실질적으로 수신자는 R/4만큼 받는다.

### 시나리오3: 4개의 송신자와 유한 버퍼를 갖는 라우터, 그리고 멀티홉 경로

마지막 시나리오는 아래 그림처럼,

- 2홉 경로를 통해 패킷을 전송한다.
- 각각의 호스트가 안정적인 데이터 전송 서비스를 실행하기 위해 타임아웃/재전송 메커니즘을 사용한다.
- 모든 호스트는 람다(in)의 동일한 값을 갖고
- 모든 라우터 링크는 R바이트/초 용량을 갖는다.

![Untitled](https://user-images.githubusercontent.com/86337233/211454704-dbe234c3-f42c-4129-a971-03994afbfad0.png)

라우터 R1, R2를 지나가는 호스트 A에서 호스트 C까지의 연결을 고려해 보면, A-C, C-A로 가는 연결들은 모두 지나가는 라우터가 다르다.

시나리오 1과 2처럼 처리량은 제공된 부하와 거의 같다.

이 경우, 오버플로가 발생하지 않으므로, 처리량이 조금 더 커진다.

그래서 아래 그림처럼, 일정 수준의 데이터 양은 송신 데이터 처리양이 작은 값일 때, 수신 데이터 처리양과 같이 증가한다.

![Untitled](https://user-images.githubusercontent.com/86337233/211454705-89d22fd0-1433-4a11-ac8b-3f284d3e4dbb.png)

만약 람다(in)의 값이 매우 커진다면, 라우터 R2의 경우, A-C, B-D 트래픽을 나눠가진다고 보면 된다.(서로 트래픽이 줄어들면 반대쪽 트래픽을 늘리는 구조다.)

이를 통해 제공된 부하와 처리량 간의 트레이드오프(하나가 증가하면 하나가 감소함)가 발생함을 보여준다.

만약 혼잡때문에 패킷을 버린다면 해당 패킷들은 낭비된 것이다.

## 혼잡 제어에 대한 접근법

크게 두가지로 나뉜다.

1. 종단 간의 혼잡 제어

   네트워크 계층에서 혼잡의 존재는 단지 관찰된 네트워크 동작에 기초하여 종단 시스템이 추측해야 한다.

   그래서 3.7.1절에서는 TCP가 혼잡 제어를 위한 종단 간의 접근 방식을 취한다는 것을 볼 수 있다.

   TCP 세그먼트의 손실은 네트워크 혼잡의 발생 표시로 간주하고 TCP는 그에 따라 윈도 크기를 줄인다.

   추가로 TCP에서 증가하는 왕복 지연값을 네트워크 혼잡 증가 지표로 사용한다.

2. 네트워크 지원 혼잡 제어

   라우터들은 네트워크 안에서 송, 수신자에게 직접적인 피드백을 제공한다.

   이 피드백은 링크의 혼잡을 나타내는 하나의 비트처럼 간단하다.

   ATM ABR(Available Bite Rate) 혼잡 제어에서 라우터는 자신이 출력 링크에 제공할 수 있는 전송률을 송신자에게 명확히 알릴 수 있게 한다.

   최근 IP와 TCP에서 네트워크 혼잡 제어를 선택적으로 구현할 수 있다.

아래 그림은 두가지 접근법에 대한 모습이다.

1.  직접 피드백은 네트워크 라우터에서 송신자에게 전형적인 초크 패킷의 형태를 갖는다.

    초크 패킷은 송신자에게 ‘나는 혼잡하다!’라고 말하는 것이다.

2.  라우터가 혼잡을 나타내기 위해 송신자에서 수신자에게로 흐르는 패킷 안의 특정 필드에 표시/수정하는 것이다.
        수신자가 해당 패킷을 수신하면, 혼잡 상태를 송신자에게 알린다.

        하지만 완전한 왕복 시간이 걸린다.
    ![](https://user-images.githubusercontent.com/86337233/211454707-13003c37-f04c-4276-8f62-9c6287bbd253.png)
