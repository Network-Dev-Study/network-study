# TCP 혼잡 제어

## 전통적인 TCP의 혼잡 제어(종단 간의 혼잡 제어)

송신자 입장에서 수신자까지 경로에 혼잡이 없으면 송신율을 높이고, 있으면 낮춘다.

하지만 이것은 3가지 의문을 제기하는데,

1. TCP 송신자는 자신의 연결에 송신자 전송 트래픽 전송률을 어떻게 제한하는가?
2. TCP 송신자는 자신과 목적지 사이 경로의 혼잡을 어떻게 감자하는가?
3. 송신자는 종단 간의 혼잡을 감자함에 따라 송신율을 변화시키기 위해 어떤 알고리즘을 사용하는가?

**1번을 먼저 살펴보면**

송신자와 수신자끼리 몇 가지 변수가 구성되는 것을 볼 수 있는데,

송신 측에서 동작하는 TCP 혼잡 제어 메커니즘은 추가적인 변수인 혼잡 윈도를 추적한다.

`cwnd` 로 표시되는 혼잡 윈도는 TCP 송신자가 네트워크로 트래픽을 전송할 수 있는 속도에 제약을 가한다.

특히 송신쪽에서 확인 응답이 안 된 데이터의 양은 `cwnd` 와 `rwnd` 의 최솟값을 초과하지 않는다.

`LastByteSent - LastByteAcked **≤ min{cwnd, rwnd}`\*\*

만약 TCP 수신 버퍼가 매우 크다면 송신자의 확인응답이 안 된 데이터의 양은 오로지 `cwnd` 에 의해 한정된다.

추가로 전송 지연이 무시된다면 송신자의 송신 속도는 대략 `cwnd/RTT` 정도 걸린다.

**2번을 살펴보면**

타임아웃 또는 수신자로 부터 3개의 중복된 ACK를 받았을 때,

TCP 송신자 측에서 해당 세그먼트가 손실되었다고 생각할 것이다.

과도한 혼잡이 발생할 경우, 경로에 있는 하나 이상의 라우터 버퍼들이 오버플로되고, 결국 데이터그램이 버려진다.

결국 손실이벤트가 현재 혼잡 상태임을 알려주는 격이 된다.

만약 손실 이벤트가 발생하지 않는 네트워크가 혼잡이 없는 경우,

확인응답 안된 세그먼트들에 대한 확인응답들이 TCP 송신자에게 수신되고,

모든 것이 올바르게 동작하고 있다는 표시로 해당 확인응답들의 도착을 받아들이고,

TCP는 혼잡 윈도 크기를 증가시키기 위해 확인응답을 사용할 것이다.(송신자가 수신자에게 확인응답을 보내는 것이 아닌 송신자가 받은 확인응답의 속도를 `cwnd` 에 적용 하는 것이다.)

TCP는 확인응답을 혼잡 윈도 크기의 증가를 유발하는 트리거 또는 클록으로 사용하므로 **자체 클로킹**이라고 한다.

**3번을 살펴보면**

먼저 전체 TCP 송신을 너무 빠르게 송신하면 아래 그림처럼 혼잡 붕괴가 나타난다.

![Untitled](https://user-images.githubusercontent.com/86337233/211454705-89d22fd0-1433-4a11-ac8b-3f284d3e4dbb.png)

그렇다면 가용한 대역폭을 모두 사용하며 네트워크를 혼잡시키지 않으려면 전송률을 어떻게 해야할까?

TCP 송신자들은 명시적으로 조정되는 것일까?

TCP 송신자들이 로컬 정보에만 근거하여 자신들의 전송률을 정하는 분산 방식이 있는 것일까?

TCP는 다음과 같은 처리 원칙에 따라 이렇게 말한다.

- **손실된 세그먼트는 혼잡을 의미하며, 이에 따라 TCP 전송률은 한 세그먼트를 손실했을 때 줄여야 한다.**

- **확인응답된 세그먼트는 네트워크가 송신자의 세그먼트를 수신자에게 전송된다는 것이고, 이에 따라 이전에 확인응답되지 않은 세그먼트에 대해 ACK가 도착하면 송신자의 전송률은 증가할 수 있다.**

- **대역폭 탐색**
  TCP의 전략은 손실 이벤트가 일어나기 전까지 전송률을 조금씩 증가시키게 하는 것이고, 손실 이벤트가 발생하면 전송률을 줄이는 것이다.
  네트워크에 의한 혼잡 상태의 어떠한 명시적인 신호가 없으며, 각 TCP 송신자들은 다른 TCP 송신자들과는 비동기적으로 로컬 정보에 근거하여 동작한다.

이런 개념을 바탕으로, **TCP 혼잡 제어 알고리즘(TCP congestion-control algorithm)**을 상세히 고려할 수 있다.

해당 알고리즘은 3가지 구성요소를 갖는다.

1. 슬로 스타트
2. 혼잡 회피
3. 빠른 회복

여기서 1, 2번은 필수 요소이지만, 3번은 선택 사항(권고)이다.

### 슬로 스타트

TCP 연결이 시작될 때, `cwnd` 는 일반적으로 1MSS로 초기화되므로 초기 전송률은 MSS/RTT가 된다.

하지만 TCP 송신자의 가용 대역폭은 초기 전송률 보다 훨씬 크므로, 확인응답 하나를 받을 때 마다 1MSS 씩 `cwnd`가 증가한다.

아래 그림은 슬로스타트의 모습을 보여준다.

여기서 세그먼트의 개수는 점점 1 → 2 → 4씩 증가하므로 지수적으로 증가함을 알 수 있다.

![Untitled](https://user-images.githubusercontent.com/86337233/211625835-f36ebe84-04de-4091-86a2-fcedfb50fe4f.png)

그렇다면 이 지수적 증가는 언제 끝날까?

슬로스타트는 이 질문에 몇 가지 답을 제공한다.

1. 타임아웃이 있을 경우 `cwnd` 값을 1로 설정하고 새로 시작한다.

   그리고 송신자는 두 번째 상태 변수인 `ssthresh(slow start threshold(슬로 스타트 임계값))`값을 `cwnd/2`로 정한다.

2. `ssthresh`는 혼잡이 마지막으로 검출된 시점에서의 `cwnd`값의 반이므로, 이 값에 도달하거나 지나칠 때 `cwnd`를 계속 두 배로 하는 것은 신중하지 못하다.

   따라서 `cwnd` 값이 `ssthresh`와 같다면, 슬로 스타트는 종료되고, TCP는 혼잡 회피 모드로 전환한다.

   TCP는 여기서 좀 더 `cwnd`를 조심스럽게 증가시킨다.

3. 만약 3개의 ACK가 검출되면, TCP는 빠른 재전송을 수행하여 빠른 회복 상태로 들어간다.

   아래 그림처럼 TCP혼잡 제어의 FSM 설명으로 요약된다.

![Untitled](https://user-images.githubusercontent.com/86337233/211625829-2117ddf7-f325-4168-86cb-39d6bac3e2bd.png)

### 혼잡 회피

위의 슬로 스타트를 지나서 혼잡 회피 상태로 들어갔다.

현재 혼잡이 마지막으로 발견된 시점의 값의 반이므로,

TCP는 좀 더 보수적인 접근법을 채택하여 RTT마다 하나의 MSS만큼 `cwnd` 값을 증가시킨다.

만약 RTT마다 `cwnd`값이 증가하다가 타임아웃이 발생하면

슬로 스타트처럼 `cwnd`의 값은 `1MSS`로 설정하고, `ssthresh`의 값은 당시 `cwnd의 반`으로 설정한다.

하지만 중복된 ACK 이벤트가 발생한다면,

네트워크는 송신자로부터 수신자에게 계속 전달함을 의미하므로 타임아웃 케이스보다 덜 과감해야 한다.

이 때는 `cwnd`의 값을 반으로 줄이고 `ssthresh` 값을 `cwnd` 값의 반으로 기록한 후, 빠른 회복 상태로 들어간다.

### 빠른 회복

`cwnd` 값을 손실된 세그먼트에 대해 수신된 모든 중복된 ACK에 대해 `1MSS`만큼씩 증가시킨다.

손실된 세그먼트에 대한 ACK가 도착하면 TCP는 `cwnd` 혼잡 회피 상태로 들어간다.

만약 타임아웃이 발생하면 빠른 회복은 슬로 스타트 및 혼잡 회피에서와 같은 동작을 수행한 후 슬로 스타트로 전이한다.

TCP 타호 → 초기 TCP 버전, 손실이 발생하면 무조건 혼잡 윈도를 1MSS로 줄이고, 슬로 스타트 단계로 들어간다.

TCP 리노 → 새로운 TCP 버전, 빠른 회복을 적용했다.

아래 그림은 타호와 리노에 대한 TCP 혼잡 윈도 변화다.

![Untitled](https://user-images.githubusercontent.com/86337233/211625839-e0b75f39-a78a-4265-aad1-b9382257e8de.png)

타호는 그림처럼 손실이 발생할 경우, 혼잡 윈도를 1로 낮춰버리지만,

리노는 임계값과 동일하게 진행하여 혼잡 윈도를 하나씩 늘려버린다.

이 과정을 크게 본다면, 아래 그림과 같은 모습이 나온다.

단, 초기 슬로 스타트와 타임아웃같은 경우는 무시했다.

![Untitled](https://user-images.githubusercontent.com/86337233/211625842-798c4c59-a967-4847-b29f-4e4a3ebfcc32.png)

주기적으로 선형 증가와 절반화로 구성되어 있는데,

이를 **가법적 증가, 승법적 감소**라 부른다.

### TCP 큐빅

패킷 손실이 발생한 혼잡한 링크의 상태가 많이 바뀌지 않은 경우 TCP 큐빅은 손실 전 전송 속도에 근접하여 다음 대역폭을 신중하게 검사한다.

TCP 큐빅과 리노는 ACK 수신 시 혼잡 윈도를 늘리고 슬로 스타트와 빠른 복구 단계는 동일하지만

몇 가지 다른 점들이 있다.

- 손실이 감지되고 혼잡 제어 윈도의 감소되기 전 크기를 W(max)이고, 그 후 손실이 없다고 가정할 때 TCP 큐빅의 윈도 크기가 W(max)에 도달하는 시각을 K라고 하자
  큐빅 매개 변수들이 K 값에 따라 얼마나 빨리 W(max)에 도달하는가를 결정한다.
- 큐빅은 혼잡 윈도를 현재 시각 t와 K시각 사이 거리의 세제곱 함수로 증가시킨다.
  따라서 t가 K에서 더 멀리 떨어지면 혼잡 윈도 크기 증가가 훨씬 더 커진다.
  큐빅은 W(max)에 가까워지면 TCP 전송속도를 빠르게 증가시킨 다음, W(max)에 가까워지면 대역폭을 조심스럽게 탐지한다.
- t가 K보다 크면 혼잡 윈도는 급격히 커진다.
  이로 인해 링크의 정체 수준이 크게 변경된 경우 큐빅이 새 작동 지점을 더 빨리 찾을 수 있다.

아래 그림은 리노와 큐빅의 성능을 그래프로 나타낸 것이다.

![Untitled](https://user-images.githubusercontent.com/86337233/211625843-6a80951a-f492-41bc-9cf2-635b8159ce7b.jpg)

2014년 가장 인기 있는 5000개 웹 서버에서 50%가 TCP 큐빅을 사용하고 있으며, 리눅스 운영 체제에서 사용되는 TCP의 기본 버전이다.

### TCP 리노 처리율의 거시적 설명

선형적으로 W(max)에서 W(max)의 절반을 왔다 갔다하므로 W(max)\*0.75/RTT정도 평균적으로 나온다.

## 네트워크 지원 명시적 혼잡 알림과 지연 기반 혼잡 제어

### 명시적 혼잡 알림(Explict Congestion Notification, ECN)

인터넷 내에서 수행되는 네트워크 지원 혼잡 제어의 한 형태로, 아래 그림 처럼 TCP와 IP가 모두 관련되어 있다.

네트워크 계층에서 IP 데이터그램 헤더의 서비스 유형 필드에 있는 2비트가 ECN에 사용된다.

ECN 비트의 한 설정은 라우터가 정체를 겪고 있음을 나타내기 위해 라우터에서 사용된다.

그 다음 IP 데이터그램에서 목적지 호스트로 전달되어 아래 그림 처럼 송신 호스트에게 알린다.

이는 직관적으로 손실이 발생하기 전에 혼잡시작을 송신자에게 알리기 위해 혼잡 알림 비트를 설정할 수 있다.

![Untitled](https://user-images.githubusercontent.com/86337233/211625847-eee59d74-7fa9-4570-adf2-2d007837b231.png)

두 번째 설정은 발신 호스트가 라우터에게 송신자와 수신자가 ECN을 사용할 수 있음을 알리고,

이에 따라 ECN으로 표시된 네트워크 혼잡에 대한 응답으로 조치를 취할 수 있음을 알리는 데 사용된다.

위 그림 처럼 수신 호스트의 TCP가 수신 데이터그램을 통해 ECN을 수신하면

수신 호스트의 TCP는 수신자-송신자 TCP ACK 세그먼트의 ECE(ECN Echo)비트를 설정하여

송신 호스트의 TCP에 혼잡 표시를 알린다.

TCP 송신자는 빠른 재전송을 사용하여

손실된 세그먼트에 반응하는 것 처럼 혼잡 윈도를 절반으로 줄여

혼잡 알림 표시가 있는 ACK에 반응하고

다음 전송되는 TCP 수신자 세그먼트 헤더에 CWR 비트를 1로 설정한다.

TCP외 다른 트랜스포트 계층 프로토콜들도 ECN을 사용하고 있다.

데이터그램 혼잡 제어 프로토콜은 ECN을 활용하여

적은 오버헤드, 혼잡 제어되는 UDP와 같은 신뢰할 수 없는 서비스를 제공한다.(UDP처럼 운영되지만 ECN을 활용하여 오버헤드를 줄인다는 의미 같습니다.)

### 지연 기반 혼잡 제어

위에서 혼잡해지는 라우터는 그 라우터에서 버퍼가 가득 차서 패킷들이 삭제되기 전에 송신자에게 혼잡 시작을 알리는 혼잡 알림 비트를 설정할 수 있다.

두번째 혼잡 회피 방식은 패킷 손실이 발생하기 전에 혼잡 시작을 사전에 감지한다.

TCP 베가스는 모든 확인응답된 패킷에 대한 RTT를 측정한다.

RTT(min)을 모든 RTT 중의 최솟값이라 할 때, TCP 베가스의 혼잡 윈도 크기가 cwnd인 경우, 혼잡하지 않을 때 처리율은 cwnd/RTT(min)가 된다.

TCP 베가스는 측정한 처리량이 위의 값과 비슷하면 아직 정체되지 않았고,

만약 처리량이 너무 낮으면 TCP 베가스는 전송 속도를 낮추게 된다.

TCP 베가스는 TCP 송신자가 파이프를 가득 채우되 그 이상으로 채우지 않도록 한다를 원칙으로 동작한다.

### 공평성

각각 다른 종단 간의 경로를 갖지만 모두 R bps의 전송률인 병목 링크를 지나가는 K개의 TCP연결을 생각해보자

병목 링크는 각 연결에 대해 연결 경로 상에 있는 모든 링크는 혼잡하지 않고 병목 링크의 전송 용량과 비교해서 충분한 전송 용량을 갖고 있음을 의미한다.

만약 각 연결의 평균 전송률이 R/K에 근접한다면 혼잡 제어 메커니즘이 공평하다고 할 것이다.

아래 그림을 보면 라우터의 용량이 R이고 2개의 TCP연결있다고 가정해 보자

두 연결은 같은 MSS, RTT를 가지며 송신할 많은 데이터를 가지고 있고 어떤 다른 연결도 이 라우터를 거치지 않는다.

그리고 슬로스타트를 생략하고 TCP 연결이 언제나 혼잡 회피 방식으로 동작한다고 가정할 것이다.

![Untitled](https://user-images.githubusercontent.com/86337233/211625853-ca717317-75e6-47ec-ac70-971a8f475fcf.png)

그렇다면 아래 그럼 처럼 처리율이 나온다.

![Untitled](https://user-images.githubusercontent.com/86337233/211625855-65fb1a01-7341-46a3-85d6-1e38f5e0be51.png)

이상적으로는 두 처리율의 합이 R과 같아야 하지만

동등한 대역폭 공유 선과 완전한 대역폭 이용선의 교차 지점 가까운 곳의 처리율을 얻는다.

A: 여기서는 공동으로 소비되는 링크 대역폭의 양이 R보다 적으므로 MSS를 하나씩 늘려가며 45도의 각도로 B지점으로 이동한다.

B: 패킷 손실이 나며, 1과 2 모두 손실 윈도를 반으로 줄여 B의 중간 값인 C로 이동하게 된다.

C, D에서도 이런 과정을 반복하여 결국 동등한 대역폭 공유 선에서 왔다갔다한다.

### 공평성과 UDP

이렇게 처리양이 가변적이라서 멀티미디어 애플리케이션들은 UDP를 선호한다.

사용자 입장에서는 공평하게 한다고 UDP의 속도를 일정 속도로 맞춘다고 해도

TCP입장에서는 UDP는 공평하지 못한다고 본다.(협력하지도 않고, 속도를 조절하지도 못하기 때문이다.)

TCP 혼잡 제어 때문에 UDP 송신자들이 TCP 트래픽을 밀어낼 가능성이 있다.

### 공평성과 병렬 TCP 연결

거의 대부분 다중 병렬 연결을 통해 연결된 n개의 연결만큼 전송률을 n으로 나눠서 사용해야 한다.

이는 기존의 덜 나눠쓰던 애플리케이션 입장에서는 불공평해 보일 수 있다.

번외: TCP 분할

클라우스 서비스에서 높은 수준의 반응성을 제공하는 것은 바람직하다.

만약 단말기가 데이터센터로 부터 멀리 떨어져 있으면 RTT값이 커질 것이고 슬로 스타트때문에 성능 저하가 발생할 것이다.

처음 연결을 시도하려고 한다면 핸드셰이크 과정으로 세그먼트를 받기 까지 `4RTT`가 걸린다.

이를 해결하기 위해 프론트엔드 서버를 사용자 가까이 구축하고

프론트엔드 서버 TCP 연결을 나누는 TCP 분할을 사용하는 것이다.

이렇게 접근한다면 `RTT(FE)*4 + RTT(BE) + 처리 시간`이 된다.

만약 프론트엔드 서버가 클라이언트와 가깝다면 이 응답시간은 `RTT + 처리 시간`이 된다.(`RTT(FE)`는 무시할 정도로 작고 `RTT(BE)`가 `RTT`와 같기 따문이다.)
