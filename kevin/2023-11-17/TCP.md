# 연결지향형 트랜스포트: TCP

## TCP 연결

핸드셰이크와 같은 연결과정은 두 통신종단시스템의 TCP에 존재하는 상태를 공유하는 논리적인 것이다.(중간 라우터들은 TCP라고 인지하지 않는다.)

TCP연결은 전이중 서비스를 제공한다. 만약 A-B 간의 TCP연결이라면, 애플리케이션 계층 데이터는 B에서 A, A에서 B로 흐를 수 있다.

그리고 항상 단일 송신자와 단일 수신자 사이의 점대점이다.(한 송신자가 여러 수신자에게 데이터를 전송할 수 없다.)

TCP연결이 어떻게 설정되는지 살펴보자면,

1. 클라이언트 애플리케이션 프로세스는 서버 프로세스와 연결을 설정하기 원한다고 TCP클라이언트에게 알린다. `clientSocket.connect((severName, serverPort))`
2. 클라이언트 트랜스포트 계층은 서버의 TCP와 TCP 연결 설정을 진행한다. (클라이언트가 먼저 특별한 TCP세그먼트를 보낸다.)
3. 서버는 두 번째 특별한 TCP 세그먼트로 응답한다.
4. 클라이언트가 세 번째 특별한 세그먼트로 다시 응답한다.

1, 2번째 세그먼트에는 페이로드(애플리케이션 계층에서 나온 데이터)가 없지만, 세 번째 세그먼트에는 페이로드를 포함할 수 있다.

TCP연결이 설정되면, 두 애플리케이션 프로세스는 서로 데이터를 보낼 수 있다.

소켓을 통해 데이터를 보내면, 이제 데이터는 클라이언트의 TCP에 맡겨진다.

![Untitled](https://user-images.githubusercontent.com/86337233/211437579-b86e832e-cd39-4707-a212-9ee7c7d6869f.png)

TCP명세서에 TCP는 ‘자신이 편한 대로 세그먼트의 데이터를 전송해야 한다.’라고 기술하고 있으며, TCP가 언제 버퍼된 데이터를 전송해야 하는 지 기술하고 있지 않다.

세그먼트로 모을 수 있는 최대 데이터의 양은 최대 세그먼트 크기(maximum segment size, MSS)로 제한된다.

MSS는 일반적으로

- 로컬 송신 호스트에 의해 전송될 수 있는 가장 큰 링크 계층 프레임의 길이(최대 전송 단위(maximum transmission unit, MTU))에 의해 일단 결정되고,
- 그 후 TCP 세그먼트(IP 데이터그램 안에 캡슐화되었을 때)와 TCP/IP 헤더 길이(통상 40바이트)가 단일 링크 계층 프레임에 딱 맞도록 하여 정해진다.

이더넷과 PPP링크 계층 프로토콜은 모두 1500바이트의 MTU를 갖는다. → 따라서 MSS의 일반적인 값은 1460바이트가 된다.(헤더 길이 40바이트 제외, MSS는 세그먼트에 있는 애플리케이션 계층 데이터에 대한 최대 크기이다.)

이렇게 MSS를 정해기 위해 먼저 링크 계층에서 MTU를 찾는다.

TCP는 TCP 헤더와 클라이언트 데이터를 하나로 짝지어 TCP세그먼트를 구성한다.

세그먼트는 네트워크 계층에 전달되며, 네트워크 계층 IP 데이터 그램 안에 각각 캡슐화 된다.

위 그림처럼 TCP가 상대에게서 세그먼트를 수신했을 때 세그먼트의 데이터는 TCP 연결의 수신 버퍼에 위치한다.

TCP 연결은 한쪽 호스트에서의 버퍼, 변수, 프로세스에 대한 소켓 연결과 다른 쪽 호스트에서의 버퍼, 변수, 프로세스에 대한 소켓 연결의 집합으로 이루어진다는 사실을 알 수 있다.

## TCP 세그먼트 구조

헤더 필드 + 데이터 필드로 구성되어 있다.

TCP가 용량이 큰 파일을 전송할 때, 일반적으로 MSS의 크기로 파일을 분절한다.

하지만 많은 대화식 애플리케이션에서는 MSS보다 작은 양의 데이터를 전송한다.

![Untitled](https://user-images.githubusercontent.com/86337233/211437603-f0cab27b-5fc5-4dd3-a7e5-b6d4a23797e7.png)

위의 그림과 같은 구조를 가지고 있으며 각각의 필드는 다음과 같다.

- 32비트 순서 번호 필드와 32비트 확인응답 번호 필드: 이전에 신뢰적인 데이터 전송 서비스 구현에서 사용된다.
- 16비트 수신 윈도: 흐름 제어에 사용된다.
- 4비트 헤더 길이 필드: 32비트 워드 단위로 TCP헤더의 길이를 나타낸다. TCP헤더는 옵션 필드 때문에 가변적인 길이를 가진다.
- 선택적이고 가변적인 옵션 필드: 송, 수신자가 MSS크기로 협상하거나 고속 네트워크에서 사용하기 위한 윈도 확장 요소로 이용된다.
- 6비트 플래그 필드(수신 윈도 옆에):
  - ACK비트는 성공적으로 수신된 세그먼트에 대한 확인 응답을 포함한다.
  - RST, SYN, FIN 비트는 연결 설정과 해제에 사용된다.
  - PSH 비트가 설정될 때, 수신자가 데이터를 상위 계층에 즉시 전달해야 한다.
  - URG 비트는 이 세그먼트에서 송신 측 상위 계층 개체가 긴급으로 표시하는 데이터이다. 이 긴급 데이터의 마지막 바이트의 위치는 16비트의 긴급 데이터 포인트 필드에 의해 가리켜진다. TCP는 긴급 데이터가 존재할 때 수신 측 상위 계층 개체에게 통지해야 하고 긴급 데이터의 끝에 대한 포인터를 전달한다.

### 순서 번호와 확인응답 번호

TCP 세그먼트 헤더의 필드 중 중요한 두 가지는 `순서 번호 필드` 와 `확인응답 번호 필드` 이다.

TCP가 이 필드를 무엇으로 채우는지 먼저 살펴 보자.

TCP는 데이터를 구조화 되어 있지 않은 순서대로 정렬된 바이트 스트림으로 본다.

TCP의 순서 번호 사용은 일련의 세그먼트에 대한 것이 아닌 전송된 바이트의 스트림에 대해서라는 관점을 반영했다.

**세그먼트에 대한 순서 번호는 세그먼트에 있는 첫 번째 바이트의 바이트 스트림 번호다.**

예를 들어,

데이터 스트림은 500,000바이트로 구성된 파일

MSS는 1000바이트

데이터 스트림의 첫 번째 바이트는 0으로 설정했을 때,

아래 그림처럼 TCP는 데이터 스트림으로 부터 500개의 세그먼트들을 구성한다.

첫번째 세그먼트의 순서 번호는 0, 두 번째 세그먼트의 순서 번호는 1000… 이런 식으로 할당된다.

![Untitled](https://user-images.githubusercontent.com/86337233/211437602-133ef178-ba22-4269-86c4-7444efd50f76.png)

그렇다면 확인응답 번호를 생각해 보면 이것은 순서 번호보다 약간 까다롭다.(책 피셜)

TCP는 전이중 방식이며 호스트 A → 호스트 B로 먼저 데이터를 보낸다 하면, 호스트 B로부터 도착한 각 세그먼트는 B입장에서 A에 들어온 데이터에 대한 순서 번호를 갖는다.

**호스트 A가 자신의 세그먼트에 삽입하는 확인응답 번호는 호스트 A가 호스트 B로부터 기대하는 다음 바이트의 순서 번호다.**

TCP는 스트림에서 첫 번째 잃어버린 바이트까지의 바이트들만 확인응답하기 때문에, TCP는 누적확인응답을 제공한다.

만약 중간에 세그먼트를 받지 못했다면(순서가 다르게 세그먼트가 도착했다면), TCP에서는 이를 공식적인 규칙으로 정해둔 것이 없어 개발자 재량이지만,

해결하는 방법은 GBN처럼 나중에 받아야 할 세그먼트를 버리거나 SR처럼 중간에 받지 못한 세그먼트를 받을 때 까지 세그먼트를 가지고 있을 수 있다.

위의 그림에서는 시작 번호를 0으로 정했는데, 사실 TCP에서 송신자와 수신자끼리 임의의 시작번호를 가지고 시작한다.

그래야 이전 TCP연결에서 보내지 못한 세그먼트들을 보낼 경우, 수신자가 무시할 수 있게 하기 위해서다.

### 텔넷: 순서 번호와 응답확인 번호 사례연구

텔넷은 원격 로그인을 위해 사용되는 유명 애플리케이션 계층 프로토콜이다.

TCP에서만 실행되며, 한 쌍의 호스트들 사이에서 동작하도록 설계되었다.

텔넷은 대화형 애플리케이션인데, 데이터를 전송하는 과정에서 암호화를 하지 않아 보안에 취약하므로 많은 사람들이 SSH프로토콜을 사용한다.

예시로 호스트 A가 클라이언트, 호스트 B가 서버라고 한다면

![Untitled](https://user-images.githubusercontent.com/86337233/211437590-612a9b6b-4d54-49b3-ad1a-d0d925d64da7.png)

클라이언트와 서버의 초기 번호는 42, 79이다.

TCP연결이 설정되면, 클라이언트는 서버로 부터 79, 서버는 클라이언트로 부터 42의 순서번호가 오기를 기다릴 것이다.

여기서 데이터 필드 안의 문자 ‘C’는 1바이트의 아스키 표현을 포함한다.

3번 세그먼트가 송신되는데, 각각 보면

1. 처음 클라이언트가 서버에게 데이터를 전송할 때, 클라이언트는 서버로 부터 아무것도 받지 않았기 때문에 서버의 초기 번호와 클라이언트의 초기번호를 보낸다.
2. 서버는 해당 데이터를 받았으므로, 클라이언트에게 세그먼트를 보내는데, 다음과 같은 두 가지 목적을 갖는다.

   1. 수신하는 서버에게 데이터에 대한 확인응답을 제공한다.(서버는 클라이언트에게 앞으로 바이트 43을 기다린다는 것을 말해준다.)
   2. 문자 ‘C’를 반대로 반향되도록 하는 것이다.

   이런 확인응답은 서버-클라이언트 데이터 세그먼트상에서 **피기백된다**고 말한다.

3. 세 번째 세그먼트는 서버로부터 수신한 데이터에 대한 확인응답을 한다.

   빈 데이터 필드를 가지며 피기백되지 않는다.

   클라이언트는 순서 번호 79를 받았으므로 서버에게 앞으로 80으로 시작하는 바이트를 기다린다.

## 왕복 시간 예측과 타임아웃

타임아웃은 RTT보다 조금 더 커야 한다. 안그러면 불필요한 재전송이 발생할 것이기 때문이다.

그렇다면 얼마나 더 커야 할까? + RTT를 처음에 어떻게 측정할까?

### 왕복 시간 예측

`SampleRTT`라고 표시되는 세그먼트에 대한 RTT샘플은 세그먼트가 송신된 시간으로 부터 그 세그먼트에 대한 긍정 응답이 도착한 시간까지의 시간 길이이다.

모든 전송된 세그먼트에 대한 `SampleRTT`를 측정하는 대신, 대부분의 TCP는 한 번에 하나의 `SampleRTT` 측정만을 시행한다.

그리고 재전송된 세그먼트에 대한 시간은 측정하지 않는다.

`SampleRTT` 값은 라우터에서의 혼잡과 종단 시스템에서의 부하 변화 때문에 세그먼트 마다 시간이 다르다.

대체로 RTT를 추정하기 위해 `SampleRTT`의 평균값(=`EstimatedRTT`)으로 채택한다.

새로운 `SampleRTT`를 획득하자 마자 TCP는 다음 공식에 따라 `EstimatedRTT`를 갱신한다.

`EstimatedRTT = (1 - α) × EstimatedRTT + α × SampleRTT`

`(권장되는 α의 값 : 0.125)`

`EstimatedRTT`는 `SampleRTT`값의 가중평균임을 유념하라.(최근의 `SampleRTT`일수록, 가중치는 자동으로 높아진다.)

통계에서 이런 평균을 **지수적 가중 이동 평균(exponential weighted moving average, EWMA)**이라고 부른다.

주어진 `SampleRTT`의 가중치가 갱신 절차가 진행됨에 따라 빠르게 지수적으로 감소하므로(갱신할 때 마다 (1-α)씩 줄어드므로) EWMA에서는 지수적이라는 용어를 쓴다.

![Untitled](https://user-images.githubusercontent.com/86337233/211437598-d947f320-f340-4b47-8f64-fb2fc7558e95.png)

위의 그림은 α=1/8의 값에 대한 `SampelRTT`와 `EstimatedRTT`를 보여준다.

`SampleRTT`의 값이 매우 커도 `EstimatedRTT`는 완만하게 커지는 것을 볼 수 있다.

RTT의 예측 외에 RTT의 변화율(=`DevRTT`)을 측정하는 것도 매우 유용하다.

이는 `SampleRTT`가 `EstimatedRTT`로부터 얼마나 많이 벗어나는지에 대한 예측으로 정의한다.

`DevRTT = (1 - β) × DevRTT + β × | SampleRTT - EstimatedRTT |`

`(권장되는 β의 값 : 0.25)`

`DevRTT`의 값이 클 수록 `SampleRTT`의 값이 `EstimatedRTT`와 차이가 크다.

### 재전송 타임아웃 주기의 설정과 관리

타임아웃 주기는 `EstimatedRTT`보다 크거나 같아야 한다. 하지만 너무 커도 세그먼트를 재전송하는 데 오래 걸리므로 약간의 여윳값을 더한 값(=`TimeoutInterval`)으로 설정해야 한다.

DevRTT의 변화에 따라 여윳값이 달라진다.

`TimeoutInterval = EstimatedRTT + 4 × DevRTT`

보통 초기 `TimeoutInterval`의 값으로 1초를 권고한다.

또한 타임아웃이 발생했을 경우 `TimeoutInterval`의 값은 두배로 하여 확인응답할 후속 세그먼트에게 발생할 수 있는 조기 타임아웃을 피한다.

그러나 `EstimatedRTT`가 수정되면 `TimeoutInterval`은 위의 공식에 따라 계산된다.

## 신뢰적인 데이터 전송

앞에서 각각의 세그먼트에 타이머가 있다고 말했지만, 이는 오버헤드를 야기할 수 있다.

그래서 TCP에서는 타이머를 하나만 사용하여 단일 타이머를 따른다.

TCP송신자에 대해 매우 간소화 해서 살펴보면, 세가지 주요 이벤트가 있다.

1. 주요 이벤트 발생

   1. TCP는 애플리케이션으로 부터 데이터 수신
   2. 세그먼트로 이 데이터를 캡슐화
   3. IP에게 이 세그먼트를 넘김

   타이머가 실행 중이 아니면 c번부터 실행한다.

2. 타임아웃
   1. 타임아웃을 일으킨 세그먼트를 재전송하여 응답한다.
   2. 타이머 다시시작
3. ACK 수신

   1. TCP 변수 `SendBase`(수신 확인응답이 확인되지 않은 가장 오래된 바이트의 순서 번호)와 ACK 값 `y`를 비교
   2. TCP는 누적 확인응답을 사용하고, `y`는 `y`바이트 이전의 모든 바이트의 수신을 확인한다.
   3. 만약 `y > SendBase`이면 ACK는 이전에 확인응답 안된 하나 이상의 세그먼트들을 확인해 준 다. 따라서 `SendBase`의 값을 `y`로 갱신한다.(만약 확인응답 안 된 세그먼트들이 존재한다면 타이머를 다시 시작한다.)

   ### 몇 가지 흥미로운 시나리오

   ![Untitled](https://user-images.githubusercontent.com/86337233/211437606-210348ac-1c16-4f20-b87e-6047251daee9.png)

   1번 시나리오

   ![Untitled](https://user-images.githubusercontent.com/86337233/211437609-5d593657-1975-4515-8614-9a8cf0d2d1fe.png)

   2번 시나리오

   ![Untitled](https://user-images.githubusercontent.com/86337233/211437607-08796096-fe33-4e0b-b443-54e51db96706.png)

   3번 시나리오

TCP구현에 있어서 몇 가지 수정사항을 논의해 보면,

### 1. 타임아웃 주기의 두 배로 설정

타임아웃이 발생할 때 마다 TCP는 아직 확인응답이 안된 가장 작은 순서 번호를 가진 세그먼트를 재전송한다.

그러나 TCP는 재전송 때마다 마지막 `EstimatedRTT`와 `DevRTT`로부터 타임아웃값을 가져오는 것이 아니라 타임아웃 주기를 이전 값의 두배로 설정한다.

만약 다른 이벤트(ACK 수신, 애플리케이션으로 부터 데이터 수신)라면 `TimoutInterval`은 최근의 값들을 가져와 설정한다.

### 2. 빠른 재전송

타임아웃 주기가 때때로 비교적 긴 경우가 있다.

다행히도, 송신자는 종종 중복 ACK에 의한 타임아웃이 일어나기 전에 패킷 손실을 발견하기도 한다.

수신자는 왜 중복 ACK를 보낼까?

TCP수신자가 기다리는 다음 것 보다 더 큰 순서 번호를 가진 세그먼트를 받았을 때, TCP수신자는 그 데이터 스트림에서의 간격을 찾아낼 것이다.

TCP수신자는 부정확인응답을 할 수 없으므로 수신자는 마지막으로 수신된 순차적인 바이트를 갖는 데이터를 그냥 다시 확인응답(중복 ACK응답)한다.

![Untitled](https://user-images.githubusercontent.com/86337233/211437613-e03e0eac-251b-4e1c-8d29-c975dfa545b1.png)

위의 그림처럼 중복 ACK를 연속으로 받게될 경우, 빠른 재전송으로 손실된 세그먼트를 보낸다.

### TCP는 GBN인가 SR인가?

TCP 송신자에서 확인응답 안된 바이트의 가장 작은 순서 번호와

전송될 다음 바이트의 순서 번호를 유지해야하는 관점에서 보면 GBN과 비슷해 보이지만

GBN에서는 손실된 세그먼트부터 현재까지 전송한 세그먼트까지 다시 보낸다.

TCP에서 수정제안된 **선택적 확인응답(selective acknowledgment)**

TCP 수신자가 마지막으로 올바로 수신된 ‘순서가 맞는’ 세그먼트에 대해 누적 확인응답을 하기보다는

‘순서가 틀린’ 세그먼트에 대해 선택적으로 확인응답을 하게 한다.

이를 선택적 재전송과 결합했을 경우, SR 프로토콜과 매우 유사하다.

따라서 TCP의 오류 복구 메커니즘은 \*\*\*\*GBN과 SR 프로토콜의 혼합으로 분류하는 것이 적당하다.

## 흐름 제어

TCP는 송신자가 수신자의 버퍼를 오버플로시키는 것을 방지하기 위해 애플리케이션에게 **흐름 제어 서비스**를 제공한다.

즉, 수신하는 애플리케이션이 읽는 속도와 송신자가 전송하는 속도를 일치시키는 서비스다.

여기서 흐름 제어와 혼잡 제어는 목적이 다른데,

혼잡 제어는 송신자가 IP네트워크의 혼잡 시 송신하는 양을 줄이는 것이다.

이번 TCP는 수신자가 순서가 다른 세그먼트를 수신할 경우, 해당 세그먼트를 버린다고 가정한다.

TCP 연결상에서 호스트 A가 호스트 B에게 큰 파일을 전송할 경우, 호스트 B는 이 연결에 수신 버퍼를 할당한다.

이 때, 수신 버퍼의 크기는 `RcvBuffer`라고 명명한다.

호스트 B는 해당 버퍼를 읽고 다음과 같은 변수들을 정의한다.

- `LastByteRead`: B의 애플리케이션 프로세스에 의해 버퍼로 부터 읽힌 데이터 스트림의 마지막 바이트 번호
- `LastByteRcvd`: B에서 네트워크로부터 도착하여 수신 버퍼에 저장된 데이터 스트림의 마지막 번호

`LasyByteRcvd - LastByteRead ≤ RcvBuffer` 여야 한다.(TCP는 오버플로를 허용하지 않으므로 해당 조건을 통해 거른다.)

`rwnd` 로 명명된 수신 윈도는 버퍼의 여유 공간으로 설정된다.(해당 변수는 매번 동적으로 바뀐다.)

`rwnd = RcvBuffer - [LastByteRcvd - LastByteRead]`

![Untitled](https://user-images.githubusercontent.com/86337233/211437616-fd0b34a2-9117-4bd5-bfb0-3fe82e59e4c3.png)

B는 `rwnd`를 통해 A에게 얼마만큼 여유공간이 있는지 알려준다.

반면 A는 `LastByteSent`와 `LastByteAcked`를 유지한다.

이 두 변수의 차이는 A가 전송 확인응답이 안된 데이터의 양이다.

`rwnd`의 값보다 작은 확인응답 안된 데이터 양을 유지함으로써 A는 B의 수신 버퍼에 오버플로가 발생하지 않는다는 것을 확신한다.

이 방식에는 기술적인 문제가 있는데,

만약 `rwnd = 0`이면

B에서 애플리케이션 프로세스가 버퍼를 비우더라도, TCP는 호스트 A에게 새로운 `rwnd`로 새로운 세그먼트를 전송하지 않는다.(TCP는 전송할 데이터가 있거나, 전송해야 할 확인응답을 가진 경우에만 A에게 세그먼트를 전송할 것이다.)

이 말을 개인적으로 해석해 보자면,

A가 클라이언트이므로 A의 송신이 끝나야 TCP연결이 끝나는 것인데, A의 의사 없이 B에서 `rwnd`가 0이기 때문에 TCP연결을 차단해 버리는 일이 발생해 버린다.

이런 일을 막기 위해 TCP명세서는 A가 B의 수신 윈도가 0일 때, 1바이트 데이터로 세그먼트를 계속해서 전송하도록 요구한다.

UDP의 경우, 소켓 앞에 위치한 유한 크기의 버퍼에 세그먼트들을 쌓을 것인데, 수신 프로세스는 버퍼로 부터 매우 빠르게 세그먼트들을 읽지 않으면, 버퍼는 오버플로되고, 세그먼트를 잃어버릴 것이다.

## TCP 연결 관리

TCP연결이 어떻게 설정되고 해제되는지 살펴볼 것이다.

먼저 클라이언트 애플리케이션 프로세스는 서버에 있는 프로세스와 연결 설정하기를 원한다는 것을 클라이언트 TCP에게 알린다.

그러면 클라이언트 안의 TCP는 TCP를 이용해 서버와 TCP연결을 시작한다.

이 과정을 보면

1. 먼저 클라이언트 측 TCP는 서버 TCP에게 특별한 TCP 세그먼트를 송신한다. (수신측 애플리케이션으로 이동하지 않는다.)

   세그먼트 헤더에 SYN비트라고 불리는 하나의 플래그 비트를 1로 설정한다.(이 세그먼트를 SYN세그먼트로 부른다.)

   그리고 이 세그먼트에 최초의 순서번호(`client_isn`)를 넣는다.

2. SYN 세그먼트를 포함하는 IP 데이터그램이 서버에 도착하면 SYN 세그먼트를 추출하고 클라이언트와 연결하여 TCP 버퍼와 변수를 할당한다.

   그리고 TCP로 연결 승인 세그먼트를 송신한다.

   또한 이 세그먼트도 애플리케이션으로 이동하지 않는다.

   그러나 헤더 안에 3개의 중요한 정보를 가지고 있다.

   1. SYN 비트는 1로 설정된다.
   2. 확인응답 필드는 `client_isn+1`로 설정된다.
   3. 자신의 최초의 순서번호(`server_isn`)를 선택하고 헤더의 순서 번호 필드에 이 값을 넣는다.

   이렇게 보내면 연결 승인 세그먼트가 된다.

   때때로 SYNACK 세그먼트로 불리기도 한다.

3. 클라이언트는 이 세그먼트를 수신하면 연결에 버퍼와 변수를 할당한다.

   그 다음 클라이언트는 서버로 또 다른 세그먼트를 송신한다.

   이 세그먼트를 통해 서버의 연결 승인 세그먼트를 확인한다.

   연결이 설정되어 있기 때문에 SYN 비트는 0으로 설정(앞으로 계속 0으로 설정)하며 확인 응답 필드 안에 `server_isn + 1`값을 넣는다.

이 과정을 통해 클라이언트는 서버의 최초 순서 번호를 기억하고 처음 데이터를 보낼 때 서버 순서번호를 넣어 보낸다.

![Untitled](https://user-images.githubusercontent.com/86337233/211437617-b3a75ef9-8307-499f-b011-2bfb62f92916.png)

이런 절차를 세 방향 핸드쉐이크라 부른다.

그리고 끝나는 과정을 살펴보면

![Untitled](https://user-images.githubusercontent.com/86337233/211437618-6aea0b08-6847-450d-b5d7-a1ae129d0c56.png)

클라이언트는 FIN 비트라 불리는 플래그 비트를 1로 설정하여 세그먼트 헤더에 포함하고 있으며,

서버가 이를 수신하면 서버는 클라이언트에게 확인응답 세그먼트를 보낸다.

그리고 서버에서도 FIN 비트가 1로 설정된 세그먼트를 보낸다.

마지막으로 클라이언트에서 ACK 세그먼트를 보내면 두 호스트의 모든 자원은 할당이 해제된다.

TCP연결이 존재하는 동안 클라이언트와 서버에 상태는 계속 변화한다.

![Untitled](https://user-images.githubusercontent.com/86337233/211440563-c245132e-f149-46d6-a184-621ccb29b848.png)

![Untitled](https://user-images.githubusercontent.com/86337233/211440566-f2dc1e33-46ab-459b-8dc6-707fc963ba70.png)

## SYN 플러드 공격

세 방향 핸드셰이크 과정에서 마지막 세그먼트를 보내지 않으면 서버가 절반만 열린 연결을 종료하고 할당된 자원들을 회수한다.

여기서 SYN 플러드 공격은 고전적인 서비스 거부 공격이며

공격자들은 핸드셰이크의 세번째 단계를 완료하지 않은 상태에서 무수한 TCP SYN 세그먼트를 보낸다.

이를 통해 서버의 연결자원을 빠르게 소진시킬 수 있으나, 요즘은 SYN 쿠키가 있어서 효과적으로 막아낸다.

SYN쿠키는

1. 서버가 반만 열린 TCP연결을 만들지 않고 서버는 자신만이 아는 비밀번호뿐만 아니라

   SYN 세그먼트의 출발지, 목적지 IP주소들과 포트 번호들의 복잡한 함수로 초기 TCP 순서 번호를 만든다.

   이 초기 순서 번호를 쿠키라고 부른다.

2. 그리고 서버는 이 순서번호를 가진 SYNACK패킷을 보낸다.

   중요한 것은 SYN에 관련된 어떤 상태정보도 기억하지 않는 것이다.

3. 합법적인 클라이언트는 ACK 세그먼트를 회신한다.

   이 ACK를 받은 서버는 ACK가 이전에 보낸 SYN과 관련 있는지 확인해야한다.

   위에서 어떤 정보도 기억하지 않지만, 쿠키가 있기 때문에 서버의 해시 함수를 실행하여 쿠키와 일치하면 올바른 클라이언트라고 결론 짓고 소켓을 연다.

   만약 클라이언트가 ACK 세그먼트를 회신하지 않으면

   서버가 처음의 가짜 SYN에 대해 어떤 자원도 할당하지 않았기 때문에 처음의 SYN은 서버에 해를 끼치지 못한다.
