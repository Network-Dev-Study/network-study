## 혼잡 제어의 원리

### 혼잡의 원인과 비용

혼잡 제어를 알아보기 위해 각 경우에서 왜 혼잡이 발생하는지와 혼잡 비용에 대해 살표보자.

#### 시나리오 1: 2개의 송신자와 무한 버퍼를 갖는 하나의 라우터

> 혼잡 시나리오 1: 무한 버퍼를 가진 하나의 홉을 공유하는 2개의 연결 이미지 첨부

* **두 호스트 출발지와 목적지 사이에 단일 홉을 공유하는 연결을 갖는다**고 가정
* **호스트 A의 애플리케이션이 `λ in` 바이트/초의 평균 전송률로 연결상으로 데이터를 보내고 있다**고 가정
* **라우터는 무제한의 버퍼 공간을 갖는다**고 가정

> 혼잡 시나리오 1: 호스트 전송률의 함수로 보는 처리량과 지연 이미지 첨부

* 왼쪽 그래프는 연결 전송률의 함수로 **연결당 처리량**을 그린 것이다. `0` 과 `R/2` 사이의 전송률에 대해 수신자 측의 처리량은 송신자의 전송률과 같다. 그러나 전송률이 `R/2` 이상일 때, 두 연결 사이에서 링크 용량을 공유하기 때문에 처리량은 단지 `R/2` 에 불과하다.
* 오른쪽 그래프는 **연결당 지연 그래프**를 그린 것이다. 전송률이 `R/2` 에 근접했을 때, 평균지연은 점점 커진다. 전송률이 `R/2` 를 초과할 때, 라우터 안에 큐잉된 패킷의 평균 개수는 제한되지 않고 출발지와 목적지 사이의 평균 지연이 무제한이 된다.

시나리오 1에서는 **"패킷 도착률이 링크 용량에 근접함에 따라 큐잉 지연이 커진다."** 라는 네트워크의 비용을 알 수 있다.

#### 시나리오 2: 2개의 송신자, 유한 버퍼를 가진 하나의 라우터

> 시나리오 2: 2개의 호스트(재전송을 갖는)와 유한 버퍼를 갖는 하나의 라우터

* **라우터 버퍼의 양이 유한하다**고 가정. 즉, 버퍼가 가득 찼을 때 도착하는 패킷들은 버려진다.
* **각 연결은 신뢰적이라고 가정**. 즉, 패킷이 라우터에서 버려지면, 결국 송신자에 의해 재전송될 것이다.

> 유한 버퍼를 가진 시나리오 2 성능 (a)

* 호스트 A가 어떻게 해서든 라우터에 있는 버퍼가 비어 있는지 없는지를 알 수 있고, 버퍼가 비어 있을 때만 패킷을 송신할 수 있는 경우를 고려해 보자.
* 이러한 경우에 `λ in` 은 `λ in'` 와 같으므로 어떠한 손실도 발생하지 않고 연결의 처리량은 `λ in` 과 같다.

> 유한 버퍼를 가진 시나리오 2 성능 (b)

* 패킷이 확실히 손실된 것을 알았을 때만 송신자가 재전송하는 경우를 고려해 보자.
* 위 그래프에 따르면 부하의 값에서 수신자 애플리케이션으로 전달되는 전송률은 `R/3` 이다. 그러므로 전송된 데이터의 `R/2` 중 `0.333R` 바이트초는 원래의 데이터고, 초당 `0.166R` 바이트/초는 재전송 데이터다.
* 이 경우에 **"송신자는 버퍼 오버플로 때문에 버려진 패킷을 보상하기 위해 재전송을 수행해야 한다."**라는 네트워크의 또 다른 비용을 알 수 있다.

> 유한 버퍼를 가진 시나리오 2 성능 (c)

* 송신자에서 너무 일찍 타임아웃되어 패킷이 손실되지 않았지만 큐에서 지연되고 있는 패킷을 재전송하는 경우를 생각해보자.
* 이럴 때 원래의 데이터 패킷과 재전송 패킷 둘 다 수신자에게 도착한다. 물론 수신자는 단지 하나의 패킷 복사본만 필요하므로 재전송된 패킷을 버린다. 이런 경우 수신자가 이미 패킷의 원래 복사본을 수신했을 때 라우터에서 원래 패킷의 재전송된 복사본을 전달하는 작업은 낭비다.
* 이 경우에 **"커다란 지연으로 인한 송신자의 불필요한 재전송은 라우터가 패킷의 불필요한 복사본들을 전송하는 데 링크 대역폭을 사용하는 원인이 된다."** 라는 네트워크의 비용을 알 수 있다.

#### 시나리오 3: 4개의 송신자와 유한 버퍼를 갖는 라우터, 그리고 멀티홉 경로

* 각각의 호스트가 안정적인 데이터 전송 서비스를 실행하기 위해 타임아웃/재전송 메커니즘을 사용한다고 가정.
* 모든 호스트는 `λ in` 의 동일한 값을 갖고, 모든 라우터 링크는 R바이트/초 용량을 갖는다고 가정.

> 송신자 4개. 유한 버퍼를 가진 라우터, 멀티홉 경로

* `λ in` 이 극히 작은 경우, 버퍼 오버플로는 거의 발생하지 않고, 혼잡 시나리오 1과 2처럼 처리량은 제공된 부하와 거의 같다.
* `λ in` 이 매우 큰 경우, 라우터 R2를 고려해보자. 라우터 R2에 도착하는 A~C 트래픽은 R2에서 `λ in` 값에 관계없이, R1에서 R2까지의 링크 용량, 최대 R인 도착률을 가질 수 있다. 만약 `λ in'` 이 모든 연결에 대해 매우 크다면, R2의 B~D 트래픽 도착률은 A~C 트래픽 도착률보다 클 수 있다. A~C와 B~D 트래픽은 버퍼 공간을 R2 라우터에서 경쟁해야 하므로, R2를 성공적으로 통과하는 A~C 트래픽의 양은 B~D에서 제공된 부하가 크면 클수록 더 작아진다.
* `λ in` 이 매우 큰 시나리오에서 패킷이 두 번째 홉 라우터에서 버려질 때마다, 두 번재 홉 라우터에게 패킷을 전달하는 첫 번째 홉 라우터에서 수행된 '작업'은 '헛된' 것이 된다.
* 즉, **"패킷이 경로상에서 버려질 때, 버려지는 지점까지 패킷을 전송하는 데 사용된 상위 라우터에서 사용된 전송 용량은 낭비된 것이다"** 라는 네트워크 비용을 확인할 수 있다.

### 혼잡 제어에 대한 접근법

혼잡 제어에 대한 TCP의 구체적인 접근 방식을 크게 보면 네트워크 계층이 혼잡 제어를 목적으로 트랜스포트 계층에게 어떤 직접적인 도움을 제공하는지에 따라 혼잡 제어 접근을 구별할 수 있다.

#### 종단 간의 혼잡 제어

네트워크 계층은 혼잡 제어 목적을 위해 트랜스포트 계층에게 어떤 직접적인 지원도 제공하지 않는다. 네크워크에서 혼잡의 존재는 단지 관찰된 네트워크 동작(예: 패킷 손실 및 지연)에 대초하여 종단 시스템이 추측해야 한다.

#### 네트워크 지원 혼잡 제어

네트워크 지원 혼잡 제어에서 라우터들은 네트워크 안에서 혼잡 상태와 관련하여 송신자나 수신자 또는 모두에게 직접적인 피드백을 제공한다. 이 피드백은 링크의 혼잡을 나타내는 하나의 비트처럼 간단한데 이 방식은 IBM SNA와 DEC DECnet 구조, ATM
